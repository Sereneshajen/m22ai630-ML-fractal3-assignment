# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WHDa4GbvoGNgEK_zjqUq1CIbuyq-TAOO
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, MaxPooling2D, GlobalAveragePooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline
from PIL import Image
import os
import cv2
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder

train_val_path = '/content/drive/MyDrive/charts/train_val'
test_path = '/content/drive/MyDrive/charts/test'
label_path = '/content/drive/MyDrive/charts/train_val.csv'
train_val_labels = pd.read_csv(label_path)

# Create empty lists for images and labels
images = []
labels = []

# Loop through all subdirectories in the dataset directory
for filename in os.listdir(train_val_path):
  if filename.endswith('.png'):
  # Load the images and resize them to (128, 128) with 3 color channels
    img = cv2.imread(os.path.join(train_val_path, filename))
    img = cv2.resize(img, (128, 128))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # img = Image.open(os.path.join(train_val_dir, filename))
    img_array = np.array(img)
    # Append the array to the list of images
    images.append(img_array)
    labels.append(filename)

# Convert the string labels to numerical labels
encoder = LabelEncoder()
labels = encoder.fit_transform(labels)

# Convert the lists to NumPy arrays
images = np.array(images)
labels = np.array(labels)

# Save the arrays in NumPy format
np.save('x_train.npy', images)
np.save('y_train.npy', labels)
x_train = np.load('x_train.npy')
y_train = np.load('y_train.npy')

x_train.shape

y_train.shape

# Create empty lists for images and labels
images = []
labels = []
# Loop through all subdirectories in the dataset directory
for filename in os.listdir(test_path):
 if filename.endswith('.png'):
 # Load the images and resize them to (128, 128) with 3 color channels
  img = cv2.imread(os.path.join(test_path, filename))
  img = cv2.resize(img, (128, 128))
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

  # img = Image.open(os.path.join(test_dir, filename))
  img_array = np.array(img)
  # Append the array to the list of images
  images.append(img_array)
  labels.append(filename)
# Convert the string labels to numerical labels
le = LabelEncoder()
labels = le.fit_transform(labels)

# Convert the lists to NumPy arrays
images = np.array(images)
labels = np.array(labels)
# Save the arrays in NumPy format
np.save('x_test.npy', images)
np.save('y_test.npy', labels)
x_test = np.load('x_test.npy')
y_test = np.load('y_test.npy')

x_test.shape

y_test.shape

# define some classes from the images we have observed
image_classes = ['line', 'dot_line', 'hbar_categorical', 'vbar_categorical', 'pie']
# map the categories to the labels array i.e y_train
label_map = {'line': 0, 'dot_line': 1, 'hbar_categorical': 2, 'vbar_categorical': 3, 'pie': 4}
y_train = np.array([label_map[label] for label in train_val_labels['type']])
y_train

x_train=x_train /255
x_val=x_train /255
x_test=x_test /255

y_train_index = train_val_labels['image_index']
y_train_type = train_val_labels['type']

# Split the training images and labels into training and validation sets
from sklearn.model_selection import train_test_split
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

print("Train Images Shape:", x_train.shape)
print("Train Labels Shape:", y_train.shape)
print("Validation Images Shape:", x_val.shape)
print("Validation Labels Shape:", y_val.shape)

#cnn model
cnn_model = Sequential([
 Conv2D(filters=16 ,kernel_size=(3,3), activation='relu', input_shape=(128,128,3)),
 MaxPooling2D(pool_size=(2,2)),
 Conv2D(32, (3,3), activation='relu'),
 MaxPooling2D(pool_size=(2,2)),
 Conv2D(64, (3,3), activation='relu'),
 MaxPooling2D(pool_size=(2,2)),
 Flatten(),
 Dense(128, activation='relu'),
 Dense(5, activation='softmax')
])
# Compile the model
cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# Train the model
history = cnn_model.fit(x_train, y_train, batch_size=1000, epochs=50,validation_data=(x_val, y_val))
# Plot the obtained loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

cnn_model.evaluate(x_val,y_val)

def image_sample(x, y, index):
 plt.figure(figsize = (10,2))
 plt.imshow(x[index])
# image_label = train_val_labels.iloc[index]['type']
# plt.xlabel(image_label)
 plt.xlabel(image_classes[y[index]])

image_sample(x_val,y_val,1)
image_sample(x_val,y_val,3)
image_sample(x_val,y_val,50)
image_sample(x_val,y_val,25)
image_sample(x_val,y_val,30)
image_sample(x_val,y_val,10)#wrongly classified

y_pred = cnn_model.predict(x_val)
y_pred[:5]

y_classes = [np.argmax(element) for element in y_pred]
y_classes[:5]

y_val[:5]

image_sample(x_val,y_val,12) #actual

image_classes[y_classes[12]] #predicted

print("classification report: \n", classification_report(y_val,y_classes))

# Generate the confusion matrix
conf_mat = confusion_matrix(y_val, y_classes)
print('Confusion Matrix:')
print(conf_mat)

y_pred = cnn_model.predict(x_test)
y_pred[:5]

y_classes = [np.argmax(element) for element in y_pred]
y_classes[:5]

y_test = np.array([label_map[label] for label in train_val_labels['type']])
y_test

y_test[:5]

from keras.applications import VGG16
from keras.preprocessing.image import ImageDataGenerator
# Load the pre-trained model
vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))

# Replace the final classification layer with a new layer
x = vgg16_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(5, activation='softmax')(x)
model = tf.keras.Model(inputs=vgg16_model.input, outputs=predictions)

# Freeze the weights of all layers except the new classification layer
for layer in model.layers:
 layer.trainable = False

# Compile the model with categorical crossentropy loss and Adam optimizer
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Print the summary of the model architecture
model.summary()

# Set up data generators for image augmentation and feeding data to the model
train_datagen = ImageDataGenerator(
 rescale=1./255,
 rotation_range=20,
 width_shift_range=0.2,
 height_shift_range=0.2,
 shear_range=0.2,
 zoom_range=0.2,
 horizontal_flip=True,
 fill_mode='nearest')
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow(x_train, y_train, batch_size=32)
val_generator = val_datagen.flow(x_val,y_val, batch_size=32)

# Train the model with early stopping
from keras.callbacks import EarlyStopping
es = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)
history = model.fit(train_generator, epochs=100, validation_data=val_generator, callbacks=[es])

# Evaluate the model on the test data
test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/charts', classes =['test'],
    target_size=(128, 128),
    batch_size=16,
    class_mode='binary')

history = model.fit(train_generator, epochs=100, validation_data=test_generator, callbacks=[es])

test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))

print('Test accuracy:', test_acc)
print('Test loss:', test_loss)