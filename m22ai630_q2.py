# -*- coding: utf-8 -*-
"""m22ai630_q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cw63Ac1UDsmoocBb90d45hdDr_aj6tQi
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline
from PIL import Image
import os
import cv2

# Define the path to the image dataset directory
train_dataset_path = '/content/drive/MyDrive/train-Gurmukhi'
validation_dataset_path = '/content/drive/MyDrive/val-Gurmukhi'

from sklearn.preprocessing import LabelEncoder
# Set the path to the folder containing the 'train' folder
data_dir = train_dataset_path
# Set the image size
img_size = (32, 32)
# Create empty lists for the images and labels
images = []
labels = []
# Loop through all subdirectories in the dataset directory
for subdir in os.listdir(train_dataset_path):
    subdir_path = os.path.join(train_dataset_path, subdir)
    if os.path.isdir(subdir_path):
        # Loop through all files in the subdirectory
        for file in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, file)
            if file_path.endswith(('.tiff','.bmp')):
                img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                img = cv2.resize(img, img_size)
                # Append the image and label to the lists
                images.append(img)
                labels.append(subdir)
# Convert the string labels to numerical labels
le = LabelEncoder()
labels = le.fit_transform(labels)
# Convert the lists to NumPy arrays
images = np.array(images)
labels = np.array(labels)
# Save the arrays in NumPy format
np.save('x_train.npy', images)
np.save('y_train.npy', labels)

x_train = np.load('x_train.npy')
y_train = np.load('y_train.npy')

x_train.shape

y_train.shape

x_train[0]
plt.matshow(x_train[0])
plt.matshow(x_train[999])

# Set the path to the folder containing the 'train' folder
data_dir = validation_dataset_path
# Set the image size
img_size = (32, 32)
# Create empty lists for the images and labels
images = []
labels = []
# Loop through all subdirectories in the dataset directory
for subdir in os.listdir(validation_dataset_path):
    subdir_path = os.path.join(validation_dataset_path, subdir)
    if os.path.isdir(subdir_path):
        # Loop through all files in the subdirectory
        for file in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, file)
            if file_path.endswith(('.tiff','.bmp')):
                img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                img = cv2.resize(img, img_size)
                # Append the image and label to the lists
                images.append(img)
                labels.append(subdir)
# Convert the string labels to numerical labels
le = LabelEncoder()
labels = le.fit_transform(labels)
# Convert the lists to NumPy arrays
images = np.array(images)
labels = np.array(labels)
# Save the arrays in NumPy format
np.save('x_val.npy', images)
np.save('y_val.npy', labels)
x_val = np.load('x_val.npy')
y_val = np.load('y_val.npy')

print(x_val.shape)

y_val.shape

plt.matshow(x_val[100])

# creating a simple nn
model = keras.Sequential([
 keras.layers.Flatten(),
keras.layers.Dense(10, input_shape=(1024,),activation = 'sigmoid')
])
# compile the nn
model.compile(optimizer='adam',
 loss='sparse_categorical_crossentropy',
 metrics=['accuracy']
 )
# train the model
# some 10 iterations done here
model.fit(x_train, y_train,epochs= 10, validation_data=(x_val, y_val))

x_train_scaled = x_train/255
x_val_scaled = x_val/255
model.fit(x_train_scaled, y_train,epochs= 10, validation_data=(x_val_scaled, y_val))

model.evaluate(x_val_scaled,y_val)

plt.matshow(x_val[0])
y_predicted = model.predict(x_val_scaled)
y_predicted[1]
# this showing the 10 results for the input '0', we need to look for the value which is max
print('Predicted Value is ',np.argmax(y_predicted[1]))

# test some more values
plt.matshow(x_val[40])
print('Predicted Value is ',np.argmax(y_predicted[88]))

y_classes = [np.argmax(element) for element in y_predicted]

from sklearn.metrics import confusion_matrix, classification_report
# Generate the confusion matrix
conf_mat = confusion_matrix(y_val, y_classes)
print('Confusion Matrix:')
print(conf_mat)

print("classification report: \n", classification_report(y_val,y_classes))

model2 = keras.Sequential([
 keras.layers.Flatten(),
 keras.layers.Dense(1024,input_shape=(1024,), activation='relu'),
 keras.layers.Dense(10, activation='softmax')
])
# compile the nn
model2.compile(optimizer='adam',
 loss='sparse_categorical_crossentropy',
 metrics=['accuracy']
 )
# train the model
# some 10 iterations done here
history = model2.fit(x_train_scaled, y_train,epochs= 10, validation_data=(x_val_scaled, y_val))

model2.evaluate(x_val_scaled,y_val)

# Evaluate the model
test_loss, test_acc = model.evaluate(x_val, y_val)
print('Test accuracy:', test_acc)
# Plot the training and validation accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()